{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d3c870",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Named Entity Recognition Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de4bc80a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39bd3527-1830-412a-b08c-0f2e9a4d77c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import modin.pandas as pd_modin\n",
    "import time\n",
    "\n",
    "import modin.pandas as pd_modin\n",
    "import time\n",
    "import os\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"\n",
    "\n",
    "filepath = \"train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f5308",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "Load text dataset with entity tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd50f04c-a26e-49cf-ac33-83cf9b656b24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.25287406198913\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "pd.read_csv(filepath)\n",
    "print(time.perf_counter() -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1cdd836-d559-4311-b248-cc3deb72e241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.26845909700205\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "pd_modin.read_csv(filepath)\n",
    "print(time.perf_counter() -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12802aed-bee5-4ae7-84e7-992fbfdb65b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pd.read_csv(filepath)\n",
    "print(time.time() -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c07ce48e-f5f4-4d79-9b2e-425555253ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.269199132919312\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pd_modin.read_csv(filepath)\n",
    "print(time.time() -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bedf34e-90b5-4657-98ea-ef168e29f395",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 s, sys: 1.69 s, total: 23.5 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa0a9cfc-d8bc-4d83-8112-254dbe1d1c04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.2 s, sys: 1.11 s, total: 4.31 s\n",
      "Wall time: 9.15 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>Stuning even for the non-gamer</th>\n",
       "      <th>This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>an absolute masterpiece</td>\n",
       "      <td>I am quite sure any of you actually taking the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599994</th>\n",
       "      <td>1</td>\n",
       "      <td>Don't do it!!</td>\n",
       "      <td>The high chair looks great when it first comes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599995</th>\n",
       "      <td>1</td>\n",
       "      <td>Looks nice, low functionality</td>\n",
       "      <td>I have used this highchair for 2 kids now and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599996</th>\n",
       "      <td>1</td>\n",
       "      <td>compact, but hard to clean</td>\n",
       "      <td>We have a small house, and really wanted two o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599997</th>\n",
       "      <td>1</td>\n",
       "      <td>what is it saying?</td>\n",
       "      <td>not sure what this book is supposed to be. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599998</th>\n",
       "      <td>2</td>\n",
       "      <td>Makes My Blood Run Red-White-And-Blue</td>\n",
       "      <td>I agree that every American should read this b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3599999 rows x 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2                     Stuning even for the non-gamer  \\\n",
       "0        2              The best soundtrack ever to anything.   \n",
       "1        2                                           Amazing!   \n",
       "2        2                               Excellent Soundtrack   \n",
       "3        2  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "4        2                            an absolute masterpiece   \n",
       "...     ..                                                ...   \n",
       "3599994  1                                      Don't do it!!   \n",
       "3599995  1                      Looks nice, low functionality   \n",
       "3599996  1                         compact, but hard to clean   \n",
       "3599997  1                                 what is it saying?   \n",
       "3599998  2              Makes My Blood Run Red-White-And-Blue   \n",
       "\n",
       "        This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^  \n",
       "0        I'm reading a lot of reviews saying that this ...                                                                                                                                                                                                                                                                                                                                                          \n",
       "1        This soundtrack is my favorite music of all ti...                                                                                                                                                                                                                                                                                                                                                          \n",
       "2        I truly like this soundtrack and I enjoy video...                                                                                                                                                                                                                                                                                                                                                          \n",
       "3        If you've played the game, you know how divine...                                                                                                                                                                                                                                                                                                                                                          \n",
       "4        I am quite sure any of you actually taking the...                                                                                                                                                                                                                                                                                                                                                          \n",
       "...                                                    ...                                                                                                                                                                                                                                                                                                                                                          \n",
       "3599994  The high chair looks great when it first comes...                                                                                                                                                                                                                                                                                                                                                          \n",
       "3599995  I have used this highchair for 2 kids now and ...                                                                                                                                                                                                                                                                                                                                                          \n",
       "3599996  We have a small house, and really wanted two o...                                                                                                                                                                                                                                                                                                                                                          \n",
       "3599997  not sure what this book is supposed to be. It ...                                                                                                                                                                                                                                                                                                                                                          \n",
       "3599998  I agree that every American should read this b...                                                                                                                                                                                                                                                                                                                                                          \n",
       "\n",
       "[3599999 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pd_modin.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03064ebd-ec0a-4c20-ac8f-c098aec5ef63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ee2af-52a8-4200-9002-dc382a97bb35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3a3f8-74e1-4e38-b4f7-9c38ca17beb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61305be6-3f06-4c3a-938b-abe2fec0b6c1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4190807342529297"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "dataset = pd.read_csv(\"ner.csv\")\n",
    "time.time()- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726c3eb4-3a22-470e-8582-c9f418b1e788",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31632183901092503"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "dataset = pd.read_csv(\"ner.csv\")\n",
    "perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7ca27ac-a2a4-4da2-96e9-5c8835459326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MODIN_ENGINE\"] = \"ray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab4d21e0-6d5b-4b78-abd7-7b11d991721d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6143596172332764"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "modin_dataset = pd_modin.read_csv(\"ner.csv\")\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef5c259-46e1-4575-94ee-29957a262062",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"Sentence #\"] = dataset[\"Sentence #\"].fillna(method='ffill')\n",
    "sentences, targets = [], []\n",
    "for sent_i, x in dataset.groupby(\"Sentence #\"):\n",
    "    words = x[\"Word\"].tolist()\n",
    "    tags = x[\"Tag\"].tolist()\n",
    "    sentences.append(words)\n",
    "    targets.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe04a0b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Number of sentences in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1fe25e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22862"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d3373f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Text encoding\n",
    "\n",
    "Convert each word into subwords and their respective subword ids such that Bert can work with the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566b85f4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n"
     ]
    }
   ],
   "source": [
    "# tokenize words\n",
    "PRETRAINED = \"prajjwal1/bert-tiny\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(PRETRAINED)\n",
    "sentences_encoded = tokenizer(\n",
    "    sentences, is_split_into_words=True, return_tensors=\"pt\", padding=True, truncation=True, max_length=150, add_special_tokens=False\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b846e80d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22862, 150])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_encoded[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7319a81",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Target encoding\n",
    "\n",
    "Convert the NER tags into tensors such that Bert can work with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b0639c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-tim': 0,\n",
       " 'B-tim': 1,\n",
       " 'B-org': 2,\n",
       " 'B-gpe': 3,\n",
       " 'I-geo': 4,\n",
       " 'B-per': 5,\n",
       " 'I-eve': 6,\n",
       " 'B-art': 7,\n",
       " 'I-art': 8,\n",
       " 'I-gpe': 9,\n",
       " 'O': 10,\n",
       " 'I-org': 11,\n",
       " 'I-per': 12,\n",
       " 'B-eve': 13,\n",
       " 'B-nat': 14,\n",
       " 'B-geo': 15,\n",
       " 'I-nat': 16}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping from ner tag to number\n",
    "tag2idx = {tag: i for i, tag in enumerate(set(t for ts in targets for t in ts))}\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e34bc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pad the target tensors because sentences have different length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65c30cc0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22862, 150])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = sentences_encoded[\"input_ids\"].shape[1]\n",
    "targets_encoded = torch.empty((0, max_len), dtype=torch.long)\n",
    "\n",
    "for sent_idx, target in enumerate(targets):\n",
    "    enc = torch.full(size=(max_len,), fill_value=tag2idx['O'], dtype=torch.long)\n",
    "    # repeat ner tag for each subword\n",
    "    for word_idx, tag in enumerate(target):\n",
    "        span = sentences_encoded.word_to_tokens(sent_idx, word_idx)\n",
    "        # ignore words that tokenizer did not understand e.g. special characters\n",
    "        if span is not None:\n",
    "            start, end = span\n",
    "            enc[start:end] = tag2idx[tag]\n",
    "    targets_encoded = torch.vstack((targets_encoded, enc))\n",
    "\n",
    "targets_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055220a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Show the first sample and its target tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d815b5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thousands of demonstrators have marched through london to protest the war in iraq and demand the withdrawal of british troops from that country. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sentences_encoded[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f04998",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 10, 10, 10, 10, 10, 15, 10, 10, 10, 10, 10, 15, 10, 10, 10, 10, 10,\n",
       "          3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_encoded[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116fdbb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train/Test split\n",
    "\n",
    "Split dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c82a27",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train sentences: 18289', 'Test sentences: 4572')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * len(sentences_encoded.input_ids))\n",
    "test_size = int(0.2 * len(sentences_encoded.input_ids))\n",
    "train_sentences = sentences_encoded[:train_size]\n",
    "train_targets = targets_encoded[:train_size]\n",
    "test_sentences = sentences_encoded[train_size:train_size+test_size]\n",
    "test_targets = targets_encoded[train_size:train_size+test_size]\n",
    "(f\"Train sentences: {len(train_targets)}\", f\"Test sentences: {len(test_targets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03259852",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, labels):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ids = torch.tensor(self.sentences[index].ids)\n",
    "        mask = torch.tensor(self.sentences[index].attention_mask)\n",
    "        labels = self.labels[index].clone()\n",
    "\n",
    "        return {\n",
    "            'ids': ids,\n",
    "            'mask': mask,\n",
    "            'tags': labels\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "training_set = NERDataset(train_sentences, train_targets)\n",
    "testing_set = NERDataset(test_sentences, test_targets)\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size=16, shuffle=True)\n",
    "testing_loader = DataLoader(testing_set, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c15201",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0dfbb1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load a pretrained Bert model to fine-tune for multi-class classification of NER tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a4797e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = BertForTokenClassification.from_pretrained(PRETRAINED, num_labels=len(tag2idx))\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=2e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b9005f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "loss: 2.88024\n",
      "loss: 1.80421\n",
      "loss: 1.15632\n",
      "loss: 1.01469\n",
      "loss: 0.89944\n",
      "loss: 0.98938\n",
      "loss: 0.92672\n",
      "loss: 0.7426\n",
      "loss: 0.62529\n",
      "loss: 0.72075\n",
      "loss: 0.69993\n",
      "loss: 0.59267\n",
      "epoch: 2\n",
      "loss: 0.71214\n",
      "loss: 0.74181\n",
      "loss: 0.65504\n",
      "loss: 0.50718\n",
      "loss: 0.36026\n",
      "loss: 0.32124\n",
      "loss: 0.38675\n",
      "loss: 0.39118\n",
      "loss: 0.43116\n",
      "loss: 0.44601\n",
      "loss: 0.53579\n",
      "loss: 0.42692\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(1, 3):\n",
    "    print(\"epoch:\", epoch)\n",
    "    model.train()\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        data = {k: v.to(device) for k, v in data.items()}\n",
    "        output = model(data[\"ids\"], attention_mask=data[\"mask\"], labels=data[\"tags\"])\n",
    "        loss = output[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i % 100 == 0:\n",
    "            print(\"loss:\", round(loss.detach().cpu().item(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb3d25",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test model\n",
    "\n",
    "Compute classification metric of Bert model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72dd228e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_trues = [], []\n",
    "\n",
    "for data in testing_loader:\n",
    "    data = {k: v.to(device) for k, v in data.items()}\n",
    "    with torch.no_grad():\n",
    "        output = model(data[\"ids\"], attention_mask=data[\"mask\"], labels=data[\"tags\"])\n",
    "    loss = output[0]\n",
    "    logits = output[1].detach().cpu()\n",
    "    mask = data[\"mask\"].cpu()\n",
    "\n",
    "    label_ids = data[\"tags\"].cpu()\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    for i in range(pred_ids.shape[0]):\n",
    "        # remove pad predictions\n",
    "        pred_ids_non_pad = pred_ids[i, mask[i]]\n",
    "        label_ids_non_pad = label_ids[i, mask[i]]\n",
    "        all_preds.append(pred_ids_non_pad)\n",
    "        all_trues.append(label_ids_non_pad)\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_trues = torch.cat(all_trues)\n",
    "accuracy = accuracy_score(all_trues, all_preds)\n",
    "print(\"Test Accuracy:\", round(accuracy, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
